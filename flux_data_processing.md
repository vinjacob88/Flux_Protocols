## **Flux data processing at Cumberland Plain using PyFluxPro**
*Daniel Metzen, 2019-08-12*
*Vinod Jacob, 2022-03-10*
***
### **Summary**
All scripts used to generate L1 input files are located on my external hard drive in the flux_data_processing/scripts folder and on hie-storage in the TERN/FLUX_TOWER/AU-Cum/scripts folder. Input data files, control files and generated netCDF files are packaged for each year and in the flux_data_processing/pyfluxpro_files/AU-Cum/{YEAR} folder as well as in the TERN/FLUX_TOWER/AU-Cum/{YEAR} folder. There's also a PyFluxPro folder that I recommend to use because all file paths are relative. Thus, the flux_data_processing folder can be moved and everything should still work.

### **Creating L1 input Excel file**
The L1 input file is generated using a separate jupyter notebook for each year. The notebook also outlines changes and updates to auxillary data needed before running the PyFluxPro pipeline. The notebook are located in the flux_data_processing/scripts folder on the external hard drive and on hie-storage in the TERN/FLUX_TOWER/AU-Cum/scripts folder.

There is a **fluxdata_python_environment.yml** file in the flux_data_processing folder that can be used to create a conda environment containing all packages needed. Navigate to the flux_data_processing folder and run **conda env create -f fluxdata_python_environment.yml** in the command line. Once installed, activate the environment by running **conda activate fluxdata**. After that, you can launch jupyter notebook by running **jupyter notebook**. Next, click on the scripts folder and select the notebook you want to run and follow the instructions.

##**Step by step on creating L1 file using Jupyter notebook**

## *Installing and activating L1 environment and then opening jupyter lab*
1. Open command line
2. Got to directory with “L1_environment.yml” file
3. Type *conda env create -f L1_environment.yml* 
2. Type *conda activate L1_environment*
3. Type *jupyter lab*


### **PyfluxPro setup**
To run the PyfluxPro GUI Python3 is needed. Set-by-step instructions to set you up can be found at the [OzFlux github](https://github.com/OzFlux/PyFluxPro). There is also a stand-alone windows installer available on cloudstore. Get in touch with [Peter Isaac](mailto:pisaac.ozflux@gmail.com) to get access to the OzFlux cloudstore folder.

All control files, the input data files and generated netCDF files are packaged for each year and in the flux_data_processing/pyfluxpro_files/AU-Cum/{YEAR} folder as well as in the TERN/FLUX_TOWER/AU-Cum/{YEAR} folder.

### **Level 1**
- Read data from input file (Excel file in our case, could be csv as well)
- Assign global attributes of netCDF file, e.g. site PI information, site location and elevation, tower height, canopy height etc.
- Assign name and attributes of data variables, e.g. standard name of variable, instrument type, height and serial number, etc.

### **Level 2**
- Quality control of data using:
  - "RangeCheck" on data itself to exclude obvious outliers with unreasonable values
  - using "DependencyCheck" to remove data when other variables have been flagged using "RangeCheck", e.g. removing Fc when AGC or EddyPro QC Flag "RangeCheck" failed
  - ""DiurnalCheck" to remove data that falls outside of 3 standard deviations for a given our of day of the season.

### **Level 3 - This is the cleaned observed data**
- Fill data gaps with data of lower priority, e.g. use SONIC temperature data when gap in HMP air temperature data. If no SONIC data is available use HMP data at 7m height.
- Fc storage flux will also be added to Fc at level 3
- **Note:** Before installation of smartflux the actual calculation of 30min 'slow' data ("_PFP" variables) happened at level 3. Smartflux only used 10Hz data, and therefore a corresponding column to the 'slow' data previously generated by PyFluxPro is not available.

Query guidelines:
- Each data column is associated with a corresponding "_QCFlag" column by default in PFP. **Note:** These are not the EddyPro QC flags. A Flag of 0 for example indicated that the data has passed all QC checks, while a flag of 1 tags data that was missing in the input file and data flagged with 2 failed the range check. A complete definition of flag is available in the PFP docs folder.
- Data generated by EddyPro is indicated by a "_EP" suffix in the variable name and the 30 minute data calculated by PyFluxPro by "_PFP". **Note:** "_PFP" columns are no longer present under the smartflux data stream.
- Data variables without any suffix (e.g. "Fc"), are merged giving preference to EddyPro over PyFluxPro. For example "Fc" data contains "Fc_EP" data when present and only falls back to "Fc_PFP" when no EddyPro data is available. **Note:** After installing smartflux the "Fc" and "Fc_EP" columns are identical as all data is calculated using EddyPro in the logger before being uploaded to HIEv.
- Only data with EddyPro flags of 0 and 1 is being passed at Level 2.
- If the highest quality data (EP QC flag of 0) is needed, the variable of interest (e.g. "Fc_EP") can be extracted using the EddyPro QC column (e.g. "Fc_EP_QC") to conditionally slice the data, e.g. only return "Fc_EP" when "Fc_EP_QC"==0 is met. This can be easily done outside of PyFluxPro using your preferred data analysis tool.

### **Level 4**
- Gap-filling of drivers (radiation, temperature, soil moisture, etc.) using SOLO ANN to fit ACCESS, AWS and ERA5 data to site data
- Climatology has to be calculated from the L3 netCDF file and alternate data sources have to be downloaded from cloudstore prior to running L4
- Settings:
  - Min pts (%) = 25
  - Months = 3

### **Level 5**
- Gap-filling of flux data (Fc, Fe, Fh, ustar) using SOLO ANN to predict fluxes as function of gap-filled driver data
- SOLO ANN settings:
  - Nodes = auto
  - Training = 500
  - Nda factor = 5
  - Learning = 0.001
  - Iterations = 500
  - Min pts (%) = 10
  - Months = 3

### **Level 6 - This is the final gap-filled and partitioned data**
- Partitioning of NEE into ER and GPP using SOLO, Lloyd-Taylor and Lasslop
- 2.5% of ER "observations" removed on either side to increase signal to noise ratio and avoid over-fitting to outliers before processing with any of the above mentioned methods
- SOLO ANN sSettings:
  - Nodes = 1
  - Training = 500
  - Nda factor = 5
  - Learning = 0.001
  - Iterations = 500
  - Min pts (%) = 1
  - Months = 12